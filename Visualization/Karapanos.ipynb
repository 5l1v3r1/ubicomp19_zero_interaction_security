{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sound-Proof / Karapanos et al.\n",
    "================\n",
    "\n",
    "This notebook is used to generate the results for the evaluation of the scheme \"Sound-Proof\" by Karapanos et al. (Karapanos, Nikolaos, Claudio Marforio, Claudio Soriente, and Srdjan Capkun. \"Sound-Proof: Usable Two-Factor Authentication Based on Ambient Sound.\" In USENIX Security Symposium, pp. 483-498. 2015.). In the code, this scheme is called \"soundProofXcorr\", in the paper it is evaluated in section 4.1.\n",
    "\n",
    "First, we have to import some libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches':None}\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import copy\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import gzip\n",
    "import json\n",
    "from glob import glob\n",
    "from multiprocessing import Pool\n",
    "import random\n",
    "import seaborn as sns\n",
    "from itertools import zip_longest, combinations\n",
    "from os import makedirs\n",
    "from os.path import isfile\n",
    "import math\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to set up a number of constants that allow us to find the relevant files. Change this to point to the correct paths on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File system constants\n",
    "PREFIX=\"/media/seemoo/data/zia-data/results/\"\n",
    "PREFIX_RAW=\"/media/seemoo/data/zia-data/raw/\"\n",
    "\n",
    "PREFIX_PLOTS='/home/seemoo/plots/img'\n",
    "PREFIX_JSON='/home/seemoo/plots/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some more internal constants. Leave these alone unless you understand what you are doing. They define the pairings of sensors for the different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenarios\n",
    "S_CAR = 'CarExp'\n",
    "S_OFFICE = 'OfficeExp'\n",
    "S_MOBILE = 'MobileExp'\n",
    "\n",
    "# Subscenarios\n",
    "SU_PARKED = 'parked'\n",
    "SU_CITY = 'city'\n",
    "SU_HIGHWAY = 'highway'\n",
    "\n",
    "SU_WDAY = 'weekday'\n",
    "SU_NIGHT = 'night'\n",
    "SU_WEND = 'weekend'\n",
    "\n",
    "# (The mobile scenario did not have any subscenarios, thus none are listed here)\n",
    "\n",
    "# Sensor lists, in lists of colocated devices - all sensors listed in each list are colocated to each other \n",
    "# and not colocated with the sensors from the other list(s)\n",
    "# For the car scenario:\n",
    "CAR_SENSORS1 = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\"]\n",
    "CAR_SENSORS2 = [\"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]\n",
    "# For the office scenario:\n",
    "OFFICE_SENSORS1 = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\"]\n",
    "OFFICE_SENSORS2 = [\"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\"]\n",
    "OFFICE_SENSORS3 = [\"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\"]\n",
    "\n",
    "\n",
    "# Features - what are the internal names of the used features in the JSON files?\n",
    "TIME_FREQ_DIST = 'timeFreqDistance'\n",
    "NOISE_FP = 'noiseFingerprint'\n",
    "SOUNDPROOF = 'soundProofXcorr'\n",
    "AUDIO_FP = 'audioFingerprint'\n",
    "\n",
    "TRUONG = 'ble_wifi_truong'\n",
    "SHRESTHA = 'temp_hum_press_shrestha'\n",
    "\n",
    "\n",
    "# Intervals - which intervals should be considered? \n",
    "# All of these need to exist in the input JSON files, or the code will throw errors\n",
    "INTERVALS = ['5sec', '10sec', '15sec', '30sec', '1min', '2min']\n",
    "\n",
    "# Colocation arrays\n",
    "# These arrays are used to represent which sensors were considered colocated\n",
    "# in the two scenarios.\n",
    "#                     1  2  3  4  5  6  7  8  9 10 11 12\n",
    "COLO_CAR = np.array([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],  # 1\n",
    "                     [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],  # 2\n",
    "                     [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],  # 3\n",
    "                     [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],  # 4\n",
    "                     [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],  # 5\n",
    "                     [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],  # 6\n",
    "                     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],  # 7\n",
    "                     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],  # 8 \n",
    "                     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],  # 9\n",
    "                     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],  # 10\n",
    "                     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],  # 11\n",
    "                     [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]]) # 12\n",
    "\n",
    "# Also prepare colocation matrix for office, using a script to make it more concise.\n",
    "COLO_OFFICE = np.zeros((24, 24))\n",
    "for i in range(0, 8):\n",
    "    for x in range(0, 8):\n",
    "        COLO_OFFICE[i, x] = 1\n",
    "for i in range(8, 16):\n",
    "    for x in range(8, 16):\n",
    "        COLO_OFFICE[i, x] = 1\n",
    "for i in range(16, 24):\n",
    "    for x in range(16, 24):\n",
    "        COLO_OFFICE[i, x] = 1\n",
    "\n",
    "# Colocation information for mobile sensor scenario\n",
    "# This is more complex, as colocation changes over time. Thus the format is different, containing a list of\n",
    "# 3-tuples with start and end of a time window and the room identifier where the device was located.\n",
    "COLO_MOBILE = {}\n",
    "# Example: Sensors 2-4 was located in room 1 the whole time\n",
    "COLO_MOBILE[2] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 17, 30, 0), 1)]\n",
    "COLO_MOBILE[3] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 17, 30, 0), 1)]\n",
    "COLO_MOBILE[4] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 17, 30, 0), 1)]\n",
    "# Sensor 5 switched between rooms 1, 2 and 3 over the course of the experiment.\n",
    "COLO_MOBILE[5] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 13, 51, 0), 1),\n",
    "                  (datetime(2018, 10, 21, 13, 51, 0), datetime(2018, 10, 21, 13, 55, 0), 2),\n",
    "                  (datetime(2018, 10, 21, 13, 55, 0), datetime(2018, 10, 21, 14, 2, 0), 1),\n",
    "                  (datetime(2018, 10, 21, 14, 2, 0), datetime(2018, 10, 21, 15, 0, 0), 3),\n",
    "                  (datetime(2018, 10, 21, 15, 0, 0), datetime(2018, 10, 21, 16, 4, 0), 2),\n",
    "                  (datetime(2018, 10, 21, 16, 4, 0), datetime(2018, 10, 21, 16, 7, 0), 1),\n",
    "                  (datetime(2018, 10, 21, 16, 7, 0), datetime(2018, 10, 21, 16, 9, 0), 2),\n",
    "                  (datetime(2018, 10, 21, 16, 9, 0), datetime(2018, 10, 21, 17, 30, 0), 1)]\n",
    "\n",
    "COLO_MOBILE[6] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 13, 51, 0), 1),\n",
    "                  (datetime(2018, 10, 21, 13, 51, 0), datetime(2018, 10, 21, 13, 55, 0), 2),\n",
    "                  (datetime(2018, 10, 21, 13, 55, 0), datetime(2018, 10, 21, 14, 2, 0), 1),\n",
    "                  (datetime(2018, 10, 21, 14, 2, 0), datetime(2018, 10, 21, 15, 0, 0), 3),\n",
    "                  (datetime(2018, 10, 21, 15, 0, 0), datetime(2018, 10, 21, 16, 4, 0), 2),\n",
    "                  (datetime(2018, 10, 21, 16, 4, 0), datetime(2018, 10, 21, 16, 7, 0), 1),\n",
    "                  (datetime(2018, 10, 21, 16, 7, 0), datetime(2018, 10, 21, 16, 9, 0), 2),\n",
    "                  (datetime(2018, 10, 21, 16, 9, 0), datetime(2018, 10, 21, 17, 30, 0), 1)]\n",
    "\n",
    "COLO_MOBILE[7] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 14, 2, 0), 1),\n",
    "                  (datetime(2018, 10, 21, 14, 2, 0), datetime(2018, 10, 21, 15, 0, 0), 3),\n",
    "                  (datetime(2018, 10, 21, 15, 0, 0), datetime(2018, 10, 21, 16, 4, 0), 2),\n",
    "                  (datetime(2018, 10, 21, 16, 4, 0), datetime(2018, 10, 21, 17, 30, 0), 1)]\n",
    "\n",
    "COLO_MOBILE[8] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 14, 12, 0), 1),\n",
    "                  (datetime(2018, 10, 21, 14, 12, 0), datetime(2018, 10, 21, 15, 0, 0), 3),\n",
    "                  (datetime(2018, 10, 21, 15, 0, 0), datetime(2018, 10, 21, 16, 4, 0), 2),\n",
    "                  (datetime(2018, 10, 21, 16, 4, 0), datetime(2018, 10, 21, 16, 16, 0), 1),\n",
    "                  (datetime(2018, 10, 21, 16, 16, 0), datetime(2018, 10, 21, 16, 25, 0), 2),\n",
    "                  (datetime(2018, 10, 21, 16, 25, 0), datetime(2018, 10, 21, 17, 30, 0), 1)]\n",
    "\n",
    "COLO_MOBILE[9] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 14, 12, 0), 1),\n",
    "                  (datetime(2018, 10, 21, 14, 12, 0), datetime(2018, 10, 21, 15, 0, 0), 3),\n",
    "                  (datetime(2018, 10, 21, 15, 0, 0), datetime(2018, 10, 21, 16, 4, 0), 2),\n",
    "                  (datetime(2018, 10, 21, 16, 4, 0), datetime(2018, 10, 21, 16, 16, 0), 1),\n",
    "                  (datetime(2018, 10, 21, 16, 16, 0), datetime(2018, 10, 21, 16, 25, 0), 2),\n",
    "                  (datetime(2018, 10, 21, 16, 25, 0), datetime(2018, 10, 21, 17, 30, 0), 1)]\n",
    "\n",
    "COLO_MOBILE[10] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 14, 20, 0), 1),\n",
    "                   (datetime(2018, 10, 21, 14, 20, 0), datetime(2018, 10, 21, 15, 0, 0), 3),\n",
    "                   (datetime(2018, 10, 21, 15, 0, 0), datetime(2018, 10, 21, 16, 4, 0), 2),\n",
    "                   (datetime(2018, 10, 21, 16, 4, 0), datetime(2018, 10, 21, 17, 30, 0), 1)]\n",
    "\n",
    "COLO_MOBILE[11] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 17, 30, 0), 2)]\n",
    "COLO_MOBILE[12] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 17, 30, 0), 2)]\n",
    "COLO_MOBILE[13] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 17, 30, 0), 2)]\n",
    "COLO_MOBILE[14] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 17, 30, 0), 2)]\n",
    "\n",
    "COLO_MOBILE[15] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 10, 48, 0), 2),\n",
    "                   (datetime(2018, 10, 21, 10, 48, 0), datetime(2018, 10, 21, 10, 52, 0), 3),\n",
    "                   (datetime(2018, 10, 21, 10, 52, 0), datetime(2018, 10, 21, 12, 9, 0), 2),\n",
    "                   (datetime(2018, 10, 21, 12, 9, 0), datetime(2018, 10, 21, 12, 49, 0), 1),\n",
    "                   (datetime(2018, 10, 21, 12, 49, 0), datetime(2018, 10, 21, 14, 17, 0), 2),\n",
    "                   (datetime(2018, 10, 21, 14, 17, 0), datetime(2018, 10, 21, 15, 0, 0), 3),\n",
    "                   (datetime(2018, 10, 21, 15, 0, 0), datetime(2018, 10, 21, 16, 4, 0), 1),\n",
    "                   (datetime(2018, 10, 21, 16, 4, 0), datetime(2018, 10, 21, 16, 25, 0), 2),\n",
    "                   (datetime(2018, 10, 21, 16, 25, 0), datetime(2018, 10, 21, 17, 30, 0), 1)]\n",
    "\n",
    "COLO_MOBILE[16] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 9, 28, 0), 1),\n",
    "                   (datetime(2018, 10, 21, 9, 28, 0), datetime(2018, 10, 21, 10, 48, 0), 2),\n",
    "                   (datetime(2018, 10, 21, 10, 48, 0), datetime(2018, 10, 21, 10, 52, 0), 3),\n",
    "                   (datetime(2018, 10, 21, 10, 52, 0), datetime(2018, 10, 21, 12, 9, 0), 2),\n",
    "                   (datetime(2018, 10, 21, 12, 9, 0), datetime(2018, 10, 21, 12, 49, 0), 1),\n",
    "                   (datetime(2018, 10, 21, 12, 49, 0), datetime(2018, 10, 21, 14, 17, 0), 2),\n",
    "                   (datetime(2018, 10, 21, 14, 17, 0), datetime(2018, 10, 21, 15, 0, 0), 3),\n",
    "                   (datetime(2018, 10, 21, 15, 0, 0), datetime(2018, 10, 21, 16, 4, 0), 1),\n",
    "                   (datetime(2018, 10, 21, 16, 4, 0), datetime(2018, 10, 21, 16, 25, 0), 2),\n",
    "                   (datetime(2018, 10, 21, 16, 25, 0), datetime(2018, 10, 21, 17, 30, 0), 1)]\n",
    "\n",
    "COLO_MOBILE[17] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 14, 17, 0), 2),\n",
    "                   (datetime(2018, 10, 21, 14, 17, 0), datetime(2018, 10, 21, 15, 0, 0), 3),\n",
    "                   (datetime(2018, 10, 21, 15, 0, 0), datetime(2018, 10, 21, 16, 4, 0), 1),\n",
    "                   (datetime(2018, 10, 21, 16, 4, 0), datetime(2018, 10, 21, 16, 35, 0), 2),\n",
    "                   (datetime(2018, 10, 21, 16, 35, 0), datetime(2018, 10, 21, 17, 30, 0), 1)]\n",
    "\n",
    "COLO_MOBILE[18] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 17, 30, 0), 3)]\n",
    "COLO_MOBILE[19] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 17, 30, 0), 3)]\n",
    "COLO_MOBILE[20] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 17, 30, 0), 3)]\n",
    "COLO_MOBILE[21] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 17, 30, 0), 3)]\n",
    "\n",
    "COLO_MOBILE[22] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 9, 28, 0), 1),\n",
    "                   (datetime(2018, 10, 21, 9, 28, 0), datetime(2018, 10, 21, 12, 13, 0), 3),\n",
    "                   (datetime(2018, 10, 21, 12, 13, 0), datetime(2018, 10, 21, 12, 46, 0), 1),\n",
    "                   (datetime(2018, 10, 21, 12, 46, 0), datetime(2018, 10, 21, 17, 30, 0), 3)]\n",
    "\n",
    "COLO_MOBILE[23] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 9, 28, 0), 1),\n",
    "                   (datetime(2018, 10, 21, 9, 28, 0), datetime(2018, 10, 21, 12, 13, 0), 3),\n",
    "                   (datetime(2018, 10, 21, 12, 13, 0), datetime(2018, 10, 21, 12, 46, 0), 1),\n",
    "                   (datetime(2018, 10, 21, 12, 46, 0), datetime(2018, 10, 21, 17, 30, 0), 3)]\n",
    "\n",
    "COLO_MOBILE[24] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 17, 30, 0), 3)]\n",
    "\n",
    "COLO_MOBILE[25] = [(datetime(2018, 10, 21, 8, 30, 0), datetime(2018, 10, 21, 14, 5, 0), 1),\n",
    "                   (datetime(2018, 10, 21, 14, 5, 0), datetime(2018, 10, 21, 15, 1, 0), 2),\n",
    "                   (datetime(2018, 10, 21, 15, 1, 0), datetime(2018, 10, 21, 16, 7, 0), 3),\n",
    "                   (datetime(2018, 10, 21, 16, 7, 0), datetime(2018, 10, 21, 17, 30, 0), 1)]\n",
    "\n",
    "\n",
    "# List all available results with their respective available parameters, as an overview\n",
    "RESULTS = {\n",
    "    NOISE_FP: {\n",
    "        \"intervals\": ['5sec', '10sec', '15sec', '30sec', '1min', '2min'],\n",
    "        \"modalities\": [\"audio\"],\n",
    "        \"features\": [\"fingerprints_similarity_percent\"]\n",
    "    },\n",
    "    SOUNDPROOF: {\n",
    "        \"intervals\": ['5sec', '10sec', '15sec', '30sec', '1min', '2min'],\n",
    "        \"modalities\": [\"audio\"],\n",
    "        \"features\": [\"max_xcorr\"]\n",
    "    },\n",
    "    AUDIO_FP: {\n",
    "        \"intervals\": ['5sec', '10sec', '15sec', '30sec', '1min', '2min'],\n",
    "        \"modalities\": [\"audio\"],\n",
    "        \"features\": [\"fingerprints_similarity_percent\"]\n",
    "    },\n",
    "    TIME_FREQ_DIST: {\n",
    "        \"intervals\": ['5sec', '10sec', '15sec', '30sec', '1min', '2min'],\n",
    "        \"modalities\": [\"audio\"],\n",
    "        \"features\": [\"max_xcorr\", \"time_freq_dist\"]\n",
    "    },\n",
    "    SHRESTHA: {\n",
    "        \"intervals\": [\".\"],\n",
    "        \"modalities\": [\"temp\", \"hum\", \"press\"],\n",
    "        \"features\": [\"hamming_dist\"]\n",
    "    },\n",
    "    TRUONG: {\n",
    "        \"intervals\": ['10sec', '30sec'],\n",
    "        \"modalities\": [\"ble\", \"wifi\"],\n",
    "        \"features\": [\"euclidean\", \"jaccard\", \"mean_exp\", \"mean_hamming\", \"sum_squared_ranks\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we set up a few utility functions.\n",
    "\n",
    "First off, we need to be able to load files, which is done by the following functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File loading\n",
    "def load_file(path):\n",
    "    \"\"\"Load results from a specific file and return them as python dict.\"\"\"\n",
    "    if path.endswith('.gz'):\n",
    "        with gzip.open(path, 'rt') as fo:\n",
    "            j = json.loads(fo.read())\n",
    "            return j['results']\n",
    "    else:\n",
    "        with open(path, 'rt') as fo:\n",
    "            j = json.loads(fo.read())\n",
    "            return j['results']\n",
    "\n",
    "\n",
    "# Generate a path to a result file\n",
    "def generate_path(scenario, modality, feature, interval, sensor1, sensor2, day=None):\n",
    "    def pad_sensor(sensor):\n",
    "        return \"Sensor-\" + str(sensor).zfill(2)\n",
    "    if day is None:\n",
    "        return '/'.join([PREFIX, scenario, pad_sensor(sensor1), modality, feature, interval, pad_sensor(sensor2) + \".json.gz\"])\n",
    "    else:\n",
    "        return '/'.join([PREFIX, scenario, day, pad_sensor(sensor1), modality, feature, interval, pad_sensor(sensor2) + \".json.gz\"])\n",
    "\n",
    "\n",
    "def generate_summary_path(scenario, modality, feature, interval, sensor1, day=None, subscenario=None):\n",
    "    def pad_sensor(sensor):\n",
    "        return \"Sensor-\" + str(sensor).zfill(2)\n",
    "    if subscenario is not None:\n",
    "        filename = \"Summary-{}.json.gz\".format(subscenario)\n",
    "    else:\n",
    "        filename = \"Summary.json.gz\"\n",
    "    if day is None:\n",
    "        return '/'.join([PREFIX, scenario, pad_sensor(sensor1), modality, feature, interval, filename])\n",
    "    else:\n",
    "        return '/'.join([PREFIX, scenario, day, pad_sensor(sensor1), modality, feature, interval, filename])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to manage the data we loaded (divide it into subscenarios and determine colocation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out subscenarios\n",
    "def is_subscenario(scenario, subscenario, dt_tstamp):\n",
    "    \"\"\"Helper function to determine if a specific provided time is in a specific subscenario.\n",
    "    \n",
    "    :param scenario: The scenario (office or car)\n",
    "    :param subscenario: The subscenario we are interested in\n",
    "    :param dt_tstamp: The datetime object that should be checked.\n",
    "    :return: True if dt is within the subscenario timeframe, else False.\"\"\"\n",
    "    if subscenario is None:\n",
    "        return True\n",
    "    if scenario == S_CAR:\n",
    "        INCLUDE_INTERVALS = [(datetime(2017, 11, 23, 14, 40, 0), datetime(2017, 11, 23, 14, 46, 0), SU_PARKED),\n",
    "                             (datetime(2017, 11, 23, 14, 46, 0), datetime(2017, 11, 23, 15, 15, 0), SU_CITY),\n",
    "                             (datetime(2017, 11, 23, 15, 15, 0), datetime(2017, 11, 23, 15, 18, 0), SU_PARKED),\n",
    "                             (datetime(2017, 11, 23, 15, 18, 0), datetime(2017, 11, 23, 15, 55, 0), SU_HIGHWAY),\n",
    "                             (datetime(2017, 11, 23, 15, 55, 0), datetime(2017, 11, 23, 16, 25, 0), SU_CITY),\n",
    "                             (datetime(2017, 11, 23, 16, 25, 0), datetime(2017, 11, 23, 16, 43, 0), SU_HIGHWAY),\n",
    "                             (datetime(2017, 11, 23, 16, 43, 0), datetime(2017, 11, 23, 17, 5, 0), SU_PARKED),\n",
    "                             (datetime(2017, 11, 23, 17, 5, 0), datetime(2017, 11, 23, 17, 18, 0), SU_HIGHWAY),\n",
    "                             (datetime(2017, 11, 23, 17, 18, 0), datetime(2017, 11, 23, 17, 31, 0), SU_CITY),\n",
    "                             (datetime(2017, 11, 23, 17, 31, 0), datetime(2017, 11, 23, 17, 50, 0), SU_PARKED)]\n",
    "    elif scenario == S_OFFICE:\n",
    "        INCLUDE_INTERVALS = [(datetime(2017, 11, 27, 8, 0, 0), datetime(2017, 11, 27, 21, 0, 0), SU_WDAY),\n",
    "                             (datetime(2017, 11, 27, 21, 0, 0), datetime(2017, 11, 28, 8, 0, 0), SU_NIGHT),\n",
    "                             (datetime(2017, 11, 28, 8, 0, 0), datetime(2017, 11, 28, 21, 0, 0), SU_WDAY),\n",
    "                             (datetime(2017, 11, 28, 21, 0, 0), datetime(2017, 11, 29, 8, 0, 0), SU_NIGHT),\n",
    "                             (datetime(2017, 11, 29, 8, 0, 0), datetime(2017, 11, 29, 21, 0, 0), SU_WDAY),\n",
    "                             (datetime(2017, 11, 29, 21, 0, 0), datetime(2017, 11, 30, 8, 0, 0), SU_NIGHT),\n",
    "                             (datetime(2017, 11, 30, 8, 0, 0), datetime(2017, 11, 30, 21, 0, 0), SU_WDAY),\n",
    "                             (datetime(2017, 11, 30, 21, 0, 0), datetime(2017, 12, 1, 8, 0, 0), SU_NIGHT),\n",
    "                             (datetime(2017, 12, 1, 8, 0, 0), datetime(2017, 12, 1, 21, 0, 0), SU_WDAY),\n",
    "                             (datetime(2017, 12, 1, 21, 0, 0), datetime(2017, 12, 2, 8, 0, 0), SU_NIGHT),\n",
    "                             (datetime(2017, 12, 2, 8, 0, 0), datetime(2017, 12, 2, 21, 0, 0), SU_WEND),\n",
    "                             (datetime(2017, 12, 2, 21, 0, 0), datetime(2017, 12, 3, 8, 0, 0), SU_NIGHT),\n",
    "                             (datetime(2017, 12, 3, 8, 0, 0), datetime(2017, 12, 3, 21, 0, 0), SU_WEND),\n",
    "                             (datetime(2017, 12, 3, 21, 0, 0), datetime(2017, 12, 4, 8, 0, 0), SU_NIGHT),\n",
    "                             (datetime(2017, 12, 4, 8, 0, 0), datetime(2017, 12, 4, 21, 0, 0), SU_WDAY),\n",
    "                             (datetime(2017, 12, 4, 21, 0, 0), datetime(2017, 12, 5, 8, 0, 0), SU_WDAY)]\n",
    "    else:\n",
    "        assert False, \"Unknown scenario provided: \" + str(scenario)\n",
    "    for ts_start, ts_end, ts_subscen in INCLUDE_INTERVALS:\n",
    "        if ts_start < dt_tstamp <= ts_end:\n",
    "            return ts_subscen == subscenario\n",
    "    assert False, \"No matching timeframe found. dt=\" + str(dt)\n",
    "\n",
    "\n",
    "def is_colocated(sensor1, sensor2, scenario, dt=None):\n",
    "    \"\"\"Helper function to determine if two sensors are colocated in a specific scenario and time.\n",
    "    \n",
    "    :param sensor1: The first sensor number, as int\n",
    "    :param sensor2: The second sensor number, as int\n",
    "    :param scenario: The Scenario to consider\n",
    "    :param dt: A timestamp as string for the time to consider. Only required for mobile scenario\n",
    "    :return: true if devices are colocated, otherwise false.\"\"\"\n",
    "    # Car and office are simple lookups in their colocation tables\n",
    "    if scenario == S_CAR:\n",
    "        return COLO_CAR[sensor1-1][sensor2-1] == 1\n",
    "    if scenario == S_OFFICE:\n",
    "        return COLO_OFFICE[sensor1-1][sensor2-1] == 1\n",
    "    \n",
    "    # Mobile scenario is more involved due to mobile sensors\n",
    "    if scenario == S_MOBILE:\n",
    "        # Ensure a dt was provided\n",
    "        assert dt is not None\n",
    "        # Prepare state for locations of the three sensors\n",
    "        s1_loc = -1\n",
    "        s2_loc = -1\n",
    "        \n",
    "        # Lookup location of sensor 1 at the provided time\n",
    "        for ts_start, ts_end, ts_loc in COLO_MOBILE[sensor1]:\n",
    "            if ts_start <= dt < ts_end:\n",
    "                s1_loc = ts_loc\n",
    "                break\n",
    "        \n",
    "        # dito for sensor 2\n",
    "        for ts_start, ts_end, ts_loc in COLO_MOBILE[sensor2]:\n",
    "            if ts_start <= dt < ts_end:\n",
    "                s2_loc = ts_loc\n",
    "                break\n",
    "        \n",
    "        # Ensure we have sane locations for both\n",
    "        assert s1_loc != -1\n",
    "        assert s2_loc != -1\n",
    "        # If both are in same location => colocated. Return\n",
    "        return s1_loc == s2_loc\n",
    "    # Something is wrong, an unknown scenario identifier was provided\n",
    "    assert False, \"Unknown scenario provided: \" + scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's implement the actual loader function that load the result files and bring them into the correct representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all for feature and params\n",
    "def load_audio_feature(feature, interval, scenario, subscenario=None, strip=None):\n",
    "    \"\"\"Load an audio feature from the disk and return it as a dictionary.\n",
    "    \n",
    "    :param feature: The feature (e.g., SOUNDPROOF, AUDIO_FP, ...) to load\n",
    "    :param interval: The interval (10 seconds, 30 seconds, ...) to load\n",
    "    :param scenario: The scenario (Car or Office) to load\n",
    "    :param subscenario: The subscenario to load, or None to load the full dataset.\n",
    "    :param strip: If set, strip all keys except this one from the results (to save memory). When providing a string,\n",
    "        it will be used as a key. When providing a List of strings, all strings will be used as keys.\n",
    "    :return: The data as a dict\n",
    "    \"\"\"\n",
    "    # Ensure that the scenario is valid\n",
    "    assert scenario in [S_CAR, S_OFFICE, S_MOBILE]\n",
    "    # Logic for car scenario\n",
    "    if scenario != S_OFFICE:\n",
    "        rv = {}\n",
    "        # Set upper and lower bounds for sensor numbers\n",
    "        if scenario == S_CAR:\n",
    "            lower_bound = 1\n",
    "            upper_bound = 12\n",
    "        elif scenario == S_MOBILE:\n",
    "            lower_bound = 2\n",
    "            upper_bound = 25\n",
    "        # Go through all sensors in the experiment\n",
    "        # sensors = [2, 3, 4, 11, 12, 13, 14, 18, 19, 20, 21]\n",
    "        # for i in range(len(sensors)):\n",
    "        for s1 in range(lower_bound, upper_bound + 1, 1):\n",
    "            # s1 = sensors[i]\n",
    "            rv[s1] = {}\n",
    "            # Go through all pairs this sensor is involved in as the left-hand sensor\n",
    "            for s2 in range(s1 + 1, upper_bound + 1, 1):\n",
    "            # for j in range(i+1, len(sensors)):\n",
    "                # s2 = sensors[j]\n",
    "                # Generate the path where we expect the result file to be\n",
    "                path = generate_path(scenario, \"audio/\", feature, interval, s1, s2)\n",
    "                \n",
    "                # If we are not supposed to strip values from the results, simply load the data\n",
    "                if strip is None:\n",
    "                    # We have not yet implemented loading subscenarios without stripping\n",
    "                    assert subscenario is None, \"Unsupported combination of parameters\"\n",
    "                    \n",
    "                    # Load the results\n",
    "                    results = load_file(path)\n",
    "                    for k in results.keys():\n",
    "                        ts = parser.parse(k)\n",
    "                        rv[s1][s2][ts] = results[k]\n",
    "                    # rv[s1][s2] = load_file(path)\n",
    "                    \n",
    "                # We should strip data from the results.\n",
    "                else:\n",
    "                    # Load data\n",
    "                    results = load_file(path)\n",
    "                    # Prepare dictionary\n",
    "                    rv[s1][s2] = {}\n",
    "                    \n",
    "                    # For all keys, only include them if they are wanted\n",
    "                    for k in results.keys():\n",
    "                        ts = parser.parse(k)\n",
    "                        # If the key is not in the desired subscenario, skip it entirely\n",
    "                        if not is_subscenario(scenario, subscenario, ts):\n",
    "                            continue\n",
    "                        \n",
    "                        # If we have a list of desired keys, include all these keys\n",
    "                        if type(strip) is list:\n",
    "                            rv[s1][s2][ts] = {s: results[k][s] for s in strip}\n",
    "                        # Otherwise, we only include the \"strip\" key.\n",
    "                        else:\n",
    "                            rv[s1][s2][ts] = {strip: results[k][strip]}\n",
    "        # Return the result\n",
    "        return rv\n",
    "    # Logic for office scenario (different folder structure requires different code)\n",
    "    else:\n",
    "        rv = {}\n",
    "        # Once again, go through all combinations of sensors\n",
    "        for s1 in range(1, 25, 1):\n",
    "            rv[s1] = {}\n",
    "            for s2 in range(s1 + 1, 25, 1):\n",
    "                rv[s1][s2] = {}\n",
    "                \n",
    "                # Generate one path to load for every day of the office experiment\n",
    "                for day in [\"audio/1_0-24h/\", \"audio/2_24-48h/\", \"audio/3_48-72h/\", \"audio/4_72-96h/\", \"audio/5_96-120h/\", \"audio/6_120-144h/\", \"audio/7_144-168h/\"]:\n",
    "                    path = generate_path(scenario, \"audio/\", feature, interval, s1, s2, day=day)\n",
    "                    \n",
    "                    # If we're not stripping the results, simply load the data\n",
    "                    if strip is None:\n",
    "                        assert subscenario is None, \"Unsupported combination of parameters\"\n",
    "                        rv[s1][s2][day] = load_file(path)\n",
    "                    \n",
    "                    # Otherwise, strip again and respect subscenarios (see above)\n",
    "                    else:\n",
    "                        results = load_file(path)\n",
    "                        rv[s1][s2][day] = {}\n",
    "                        for k in results.keys():\n",
    "                            if not is_subscenario(scenario, subscenario, k):\n",
    "                                continue\n",
    "                            if type(strip) is list:\n",
    "                                rv[s1][s2][day][k] = {s: results[k][s] for s in strip}\n",
    "                            else:\n",
    "                                rv[s1][s2][day][k] = {strip: results[k][strip]}\n",
    "        # Return the assembled results\n",
    "        return rv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are used to generate False Accept Rates (FARs) and False Reject Rates (FRRs) for the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate False Accept and False Reject Rate\n",
    "def gen_far_frr(scenario, data, param, minv=None, maxv=None, increments=1000, filter_func=None, threshold=None):\n",
    "    \"\"\"Generate a bunch of statistics on the sensor pairs to allow calculation of error rates, overlap, etc.\n",
    "    \n",
    "    :param scenario: The scenario (S_CAR, S_OFFICE)\n",
    "    :param data: The data to operate on, as loaded by load_audio_feature\n",
    "    :param param: The parameter to operate on (e.g., max_xcorr)\n",
    "    :param minv: The minimum value to use for the threshold search\n",
    "    :param maxv: The maximum value to use for the threshold search\n",
    "    :param increments: The number of increments the area between minv and maxv should be divided\n",
    "    :param filter_func: A function to apply to all data before further processing, to exclude specific samples\n",
    "        that do not meet some criteria (e.g., energy too low to consider, ...)\n",
    "    :param threshold: Use a fixed threshold for computations instead of finding your own between minv and maxv.\n",
    "    :return: A dictionary containing false positive, false negative, true positive and true negative counts for\n",
    "        each considered threshold and pair of sensors.\"\"\"\n",
    "    # Histogram intersection function adapted from\n",
    "    # http://blog.datadive.net/histogram-intersection-for-change-detection/\n",
    "    def histogram_intersection(h1, h2, bins):\n",
    "        bins = np.diff(bins)\n",
    "        sm = 0\n",
    "        for i in range(len(bins)):\n",
    "            sm += min(bins[i]*h1[i], bins[i]*h2[i])\n",
    "        return sm\n",
    "    \n",
    "    # Ensure the scenario is sane\n",
    "    assert scenario in [S_CAR, S_OFFICE, S_MOBILE]\n",
    "    # Sanity check that the provided data makes sense\n",
    "    if (minv is not None and maxv is None) or (minv is None and maxv is not None):\n",
    "        raise Exception(\"Need to provide either both or none of minv, maxv\")\n",
    "    if (minv is not None and maxv is not None and threshold is not None):\n",
    "        raise Exception(\"Do not provide both a fixed threshold and an area for a threshold search.\")\n",
    "    \n",
    "    # Prepare a few variables\n",
    "    filter_res = None\n",
    "    colo = []\n",
    "    ncolo = []\n",
    "    \n",
    "    # Apply filter function. This allows us to enforce certain requirements on the data\n",
    "    # (e.g., minimum energy, ...)\n",
    "    if filter_func is not None:\n",
    "        data, filter_res = filter_func(data, scenario)\n",
    "        print(\"Filter result:\")\n",
    "        pprint(filter_res)\n",
    "    res = {}\n",
    "    \n",
    "    # Find the range (minimum and maximum values) to try for the threshold, based on the data\n",
    "    if (minv is None or maxv is None) or threshold is not None:\n",
    "        #print(\"Finding min and max...\")\n",
    "        minv = 100000.0\n",
    "        maxv = 0.0\n",
    "        if scenario == S_CAR or scenario == S_MOBILE:\n",
    "            for s1 in data:\n",
    "                for s2 in data[s1]:\n",
    "                    for d in data[s1][s2]:\n",
    "                        minv = min(data[s1][s2][d][param], minv)\n",
    "                        maxv = max(data[s1][s2][d][param], maxv)\n",
    "        if scenario == S_OFFICE:\n",
    "            for s1 in data:\n",
    "                for s2 in data[s1]:\n",
    "                    for day in data[s1][s2]:\n",
    "                        for d in data[s1][s2][day]:\n",
    "                            minv = min(data[s1][s2][day][d][param], minv)\n",
    "                            maxv = max(data[s1][s2][day][d][param], maxv)\n",
    "        print(\"min: %s, max: %s\" % (minv, maxv))\n",
    "        #print(\"Threshold fpr, fnr, tpr, tnr\")\n",
    "        \n",
    "        if 0.0 <= minv <= 1.0 and 0.0 <= maxv <= 1.0:\n",
    "            minv = 0.0\n",
    "            maxv = 1.0\n",
    "        elif 0.0 <= minv <= 100.0 and 0.0 <= maxv <= 100.0:\n",
    "            minv = 0.0\n",
    "            maxv = 100.0\n",
    "        else:\n",
    "            raise Exception(\"Not implemented\")\n",
    "\n",
    "    # Determine error counts for all considered thresholds\n",
    "    if threshold is None:\n",
    "        # Try the requested number of increments between minv and maxv\n",
    "        for i in range(increments+1):\n",
    "            # Calculate current threshold for this increment\n",
    "            threshold = minv + i * ((maxv - minv) / increments)\n",
    "            \n",
    "            res[threshold] = {}\n",
    "            \n",
    "            # If we are looking at data from the car scenario...\n",
    "            if scenario == S_CAR or scenario == S_MOBILE:\n",
    "                # ... iterate through all pairs of sensors\n",
    "                for s1 in data:\n",
    "                    res[threshold][s1] = {}\n",
    "                    for s2 in data[s1]:\n",
    "                        res[threshold][s1][s2] = {\n",
    "                            \"ta\": 0.0,  # True accept\n",
    "                            \"tr\": 0.0,  # True reject\n",
    "                            \"fa\": 0.0,  # False accept\n",
    "                            \"fr\": 0.0   # False reject\n",
    "                        }\n",
    "                        # Iterate through all readings for this pair\n",
    "                        for d in data[s1][s2]:\n",
    "                            # If the reading is above the threshold, accept it, otherwise reject\n",
    "                            accept = data[s1][s2][d][param] >= threshold\n",
    "                            # Check if we accepted correctly or incorrectly and track for error rates\n",
    "                            if is_colocated(s1, s2, scenario, d):\n",
    "                                if i == 0:\n",
    "                                    colo.append(data[s1][s2][d][param])\n",
    "                                if accept:\n",
    "                                    res[threshold][s1][s2][\"ta\"] += 1\n",
    "                                    # true_acc += 1\n",
    "                                else:\n",
    "                                    res[threshold][s1][s2][\"fr\"] += 1\n",
    "                                    # false_rej += 1\n",
    "                            else:\n",
    "                                if i == 0:\n",
    "                                    ncolo.append(data[s1][s2][d][param])\n",
    "                                if accept:\n",
    "                                    res[threshold][s1][s2][\"fa\"] += 1\n",
    "                                    # false_acc += 1\n",
    "                                else:\n",
    "                                    res[threshold][s1][s2][\"tr\"] += 1\n",
    "                                    # true_rej += 1\n",
    "            \n",
    "            # Do the same for the office (slightly more complicated due to different data structure)\n",
    "            if scenario == S_OFFICE:\n",
    "                for s1 in data:\n",
    "                    res[threshold][s1] = {}\n",
    "                    for s2 in data[s1]:\n",
    "                        res[threshold][s1][s2] = {\n",
    "                            \"ta\": 0.0,  # True accept\n",
    "                            \"tr\": 0.0,  # True reject\n",
    "                            \"fa\": 0.0,  # False accept\n",
    "                            \"fr\": 0.0   # False reject\n",
    "                        }\n",
    "                        for day in data[s1][s2]:\n",
    "                            for d in data[s1][s2][day]:\n",
    "                                accept = data[s1][s2][day][d][param] >= threshold\n",
    "                                if is_colocated(s1, s2, scenario):\n",
    "                                    if i == 0:\n",
    "                                        colo.append(data[s1][s2][day][d][param])\n",
    "                                    if accept:\n",
    "                                        res[threshold][s1][s2][\"ta\"] += 1\n",
    "                                        # true_acc += 1\n",
    "                                    else:\n",
    "                                        res[threshold][s1][s2][\"fr\"] += 1\n",
    "                                        # false_rej += 1\n",
    "                                else:\n",
    "                                    if i == 0:\n",
    "                                        ncolo.append(data[s1][s2][day][d][param])\n",
    "                                    if accept:\n",
    "                                        res[threshold][s1][s2][\"fa\"] += 1\n",
    "                                        # false_acc += 1\n",
    "                                    else:\n",
    "                                        res[threshold][s1][s2][\"tr\"] += 1\n",
    "                                        # true_rej += 1\n",
    "    \n",
    "    else:\n",
    "        # A fixed threshold has been given. Only check this threshold\n",
    "        true_acc = 0.0\n",
    "        false_acc = 0.0\n",
    "        true_rej = 0.0\n",
    "        false_rej = 0.0\n",
    "    \n",
    "        # Go through everything as before (see above), but this time do not generate\n",
    "        # a result dictionary. Instead, we just want to compute the error rates for\n",
    "        # the specified threshold and print them.\n",
    "        if scenario == S_CAR or scenario == S_MOBILE:\n",
    "            for s1 in data:\n",
    "                for s2 in data[s1]:\n",
    "                    for d in data[s1][s2]:\n",
    "                        accept = data[s1][s2][d][param] >= threshold\n",
    "                        if is_colocated(s1, s2, scenario, d):\n",
    "                            if accept:\n",
    "                                true_acc += 1\n",
    "                            else:\n",
    "                                false_rej += 1\n",
    "                        else:\n",
    "                            if accept:\n",
    "                                false_acc += 1\n",
    "                            else:\n",
    "                                true_rej += 1\n",
    "        if scenario == S_OFFICE:\n",
    "            for s1 in data:\n",
    "                for s2 in data[s1]:\n",
    "                    for day in data[s1][s2]:\n",
    "                        for d in data[s1][s2][day]:\n",
    "                            accept = data[s1][s2][day][d][param] >= threshold\n",
    "                            if is_colocated(s1, s2, scenario):\n",
    "                                if accept:\n",
    "                                    true_acc += 1\n",
    "                                else:\n",
    "                                    false_rej += 1\n",
    "                            else:\n",
    "                                if accept:\n",
    "                                    false_acc += 1\n",
    "                                else:\n",
    "                                    true_rej += 1\n",
    "\n",
    "        # Calculate error rates\n",
    "        fpr = false_acc / (false_acc + true_rej)\n",
    "        fnr = false_rej / (false_rej + true_acc)\n",
    "        tpr = true_acc / (true_acc + false_rej)\n",
    "        tnr = true_rej / (true_rej + false_acc)\n",
    "        #print(threshold, fpr, fnr, tpr, tnr)\n",
    "        # print(\"far\", fpr, \"frr\", fnr)\n",
    "        return {\"far\": fpr, \"frr\": fnr, \"threshold\": threshold}\n",
    "    \n",
    "    # Plot the overlap between the classes\n",
    "    plot_distributions(data, scenario, param, minv, maxv)\n",
    "    \n",
    "    # Also calculate overlap as a number\n",
    "    hc, bins = np.histogram(colo, np.arange(minv, maxv, maxv/100.0), density=True)\n",
    "    hn, _ = np.histogram(ncolo, np.arange(minv, maxv, maxv/100.0), density=True)\n",
    "    print(\"Intersection:\", histogram_intersection(hc, hn, bins))\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def frr_for_far(data, target_far, sources=None, targets=None):\n",
    "    \"\"\"Calculate the False Reject Rate (FRR) implied by a given target False Accept Rate (FAR).\n",
    "    Can also compute this for subsets of the datasets, given by \"sources\" and \"targets\". In this\n",
    "    case, it will consider all combinations of sources and targets (e.g., if sources = [\"1\"] and\n",
    "    targets = [\"2\", \"3\"], it will consider 1-2 and 1-3, but not 2-3).\n",
    "    \n",
    "    :param data: The data as a dictionary, as produced by gen_far_frr or the import functions.\n",
    "    :param target_far: The false accept rate to aim for. Note that 1.0 implies 100%, so 0.1% should\n",
    "        be written as 0.001.\n",
    "    :param sources: A list of sensors (as unpadded strings) to use as sources, or None if all\n",
    "        should be considered.\n",
    "    :param targets: A list of sensors (as unpadded strings) to use as targets, or NOne if all\n",
    "        should be considered\n",
    "    :return: A 3-tuple of observed FAR, FRR, and the used threshold.\n",
    "    \"\"\"\n",
    "    def is_source(sensor):\n",
    "        if sources is None:\n",
    "            return True\n",
    "        else:\n",
    "            return str(sensor) in sources\n",
    "    \n",
    "    def is_target(sensor):\n",
    "        if targets is None:\n",
    "            return True\n",
    "        else:\n",
    "            return str(sensor) in targets\n",
    "\n",
    "    # Initialize previous values with bogus values to ensure they are never used in the first iteration.\n",
    "    prev_far = -500.0\n",
    "    prev_frr = -500.0\n",
    "    prev_threshold = -500.0\n",
    "    for threshold in data:\n",
    "        false_acc = 0.0\n",
    "        false_rej = 0.0\n",
    "        true_acc = 0.0\n",
    "        true_rej = 0.0\n",
    "        for s1 in data[threshold]:\n",
    "            # Check if sensor is supposed to be included\n",
    "            if not (is_source(s1) or is_target(s1)):\n",
    "                continue\n",
    "            for s2 in data[threshold][s1]:\n",
    "                # Check if sensor pairing is supposed to be included\n",
    "                if not ((is_source(s1) and is_target(s2)) or (is_source(s2) and is_target(s1))):\n",
    "                    continue\n",
    "                # Include the numbers in the overall count\n",
    "                false_acc += data[threshold][s1][s2]['fa']\n",
    "                false_rej += data[threshold][s1][s2]['fr']\n",
    "                true_acc += data[threshold][s1][s2]['ta']\n",
    "                true_rej += data[threshold][s1][s2]['tr']\n",
    "        \n",
    "        # Calculate error rates\n",
    "        far = false_acc / (false_acc + true_rej)\n",
    "        frr = false_rej / (false_rej + true_acc)\n",
    "        \n",
    "        if far > target_far:\n",
    "            # The computed FAR is above the target FAR. Save current values and carry on\n",
    "            prev_far = far\n",
    "            prev_frr = frr\n",
    "            prev_threshold = threshold\n",
    "        else:\n",
    "            # We have reached or passed the target FAR. Determine if the previous value was a better fit\n",
    "            if abs(target_far - far) < abs(target_far - prev_far):\n",
    "                # We are closer to the target FAR than the previous FAR, use our values\n",
    "                return (far, frr, threshold)\n",
    "            else:\n",
    "                # The previous values were closer, use them\n",
    "                return (prev_far, prev_frr, prev_threshold)\n",
    "    assert False, \"This statement should never be reached. Last error rates: FAR \" + str(prev_far) + \", FRR \" + str(prev_frr)\n",
    "\n",
    "    \n",
    "def error_rate_for_threshold(data, threshold):\n",
    "    \"\"\"Calculate the error rates when using a specific threshold.\n",
    "    \n",
    "    :param data: The data, as generated by gen_far_frr\n",
    "    :param threshold: The threshold to generate the error rates for\n",
    "    :return: A 2-tuple of far, frr\n",
    "    \"\"\"\n",
    "    false_acc = 0.0\n",
    "    false_rej = 0.0\n",
    "    true_acc = 0.0\n",
    "    true_rej = 0.0\n",
    "    for s1 in data[threshold]:\n",
    "        for s2 in data[threshold][s1]:\n",
    "            # Include the numbers in the overall count\n",
    "            false_acc += data[threshold][s1][s2]['fa']\n",
    "            false_rej += data[threshold][s1][s2]['fr']\n",
    "            true_acc += data[threshold][s1][s2]['ta']\n",
    "            true_rej += data[threshold][s1][s2]['tr']\n",
    "\n",
    "    # Calculate error rates\n",
    "    far = false_acc / (false_acc + true_rej)\n",
    "    frr = false_rej / (false_rej + true_acc)\n",
    "        \n",
    "    return (far, frr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have results, we need to be able to save them. This is done by the following set of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the resulting JSON data from the get_far_frr function to a file\n",
    "def save_result_json(data, paper, interval, scenario, modality, subscenario=None, suffix=None):\n",
    "    \"\"\"Save a dictionary into a file as JSON. Mostly used for cache files.\n",
    "    \n",
    "    :param data: The data to save.\n",
    "    :param paper: The paper to save it under (SOUNDPROOF, ...)\n",
    "    :param interval: The interval to save it under\n",
    "    :param scenario: The scenario (S_CAR, S_OFFICE)\n",
    "    :param modality: The modality (max_xcorr, ...)\n",
    "    :param subscenario: The subscenario, or None if global.\n",
    "    :param suffix: A suffix to place before the .json\"\"\"\n",
    "    path = '/'.join([PREFIX_JSON, scenario, paper, modality])\n",
    "    filename = path + '/' + interval\n",
    "    if subscenario is not None:\n",
    "        filename += '-' + subscenario\n",
    "    if suffix is not None:\n",
    "        filename += '_' + suffix\n",
    "    filename += '.json'\n",
    "    makedirs(path, exist_ok=True)\n",
    "    with open(filename, 'w') as fo:\n",
    "        json.dump(data, fo, separators=(',', ': '), indent=4)\n",
    "\n",
    "# Check if a result cache file (generated by save_result_json) exists\n",
    "def result_exists(paper, interval, scenario, modality, subscenario=None, suffix=None):\n",
    "    \"\"\"Check if a cache file for a set of parameters exists.\n",
    "    \n",
    "    :param paper: The paper (SOUNDPROOF, ...)\n",
    "    :param interval: The interval\n",
    "    :param scenario: The scenario (S_CAR, S_OFFICE)\n",
    "    :param modality: The modality (max_xcorr, ...)\n",
    "    :param subscenario: The subscenario, or None if global.\n",
    "    :return: True if a file exists, otherwise False\"\"\"\n",
    "    path = '/'.join([PREFIX_JSON, scenario, paper, modality])\n",
    "    filename = path + '/' + interval\n",
    "    if subscenario is not None:\n",
    "        filename += '-' + subscenario\n",
    "    if suffix is not None:\n",
    "        filename += '_' + suffix\n",
    "    filename += '.json'\n",
    "    return isfile(filename)\n",
    "\n",
    "# Load result cache file (generated by save_result_json)\n",
    "def load_result(paper, interval, scenario, modality, subscenario=None, suffix=None):\n",
    "    \"\"\"Check if a cache file for a set of parameters exists.\n",
    "    \n",
    "    :param paper: The paper(SOUNDPROOF, ...)\n",
    "    :param interval: The interval\n",
    "    :param scenario: The scenario (S_CAR, S_OFFICE)\n",
    "    :param modality: The modality (max_xcorr, ...)\n",
    "    :param subscenario: The subscenario, or None if global.\n",
    "    :return: The loaded cache as a dictionary\"\"\"\n",
    "    assert result_exists(paper, interval, scenario, modality, subscenario, suffix)\n",
    "    rv = {}\n",
    "    \n",
    "    # Construct file name\n",
    "    path = '/'.join([PREFIX_JSON, scenario, paper, modality])\n",
    "    filename = path + '/' + interval\n",
    "    if subscenario is not None:\n",
    "        filename += '-' + subscenario\n",
    "    if suffix is not None:\n",
    "        filename += '_' + suffix\n",
    "    filename += '.json'\n",
    "    \n",
    "    # Load the data\n",
    "    with open(filename, 'r') as fo:\n",
    "        r = json.load(fo)\n",
    "    \n",
    "    # Cast thresholds to float, if necessary\n",
    "    if suffix is None:\n",
    "        for threshold in r:\n",
    "            rv[float(threshold)] = r[threshold]\n",
    "        return rv\n",
    "    else:\n",
    "        return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize FAR and FRR\n",
    "def plot_far_frr(result_data, paper=None, scenario=None, subscenario=None, modality=None, feature=None, interval=None, save=False, xlow=0.0, xhigh=1.0):\n",
    "    \"\"\"Generate the FAR and FRR for specific results data, and determine and plot the EER.\n",
    "    \n",
    "    :param result_data: data in the format generated by gen_far_frr or the import functions\n",
    "    :param xlow: lower limit for the threshold search\n",
    "    :param xhigh: upper limit for the threshold search\n",
    "    :return: A 3-tuple (threshold, fpr, fnr)\n",
    "    \"\"\"\n",
    "    # We are getting a fairly complex input, so we first have to generate a simpler data structure from it\n",
    "    if save:\n",
    "        assert paper is not None\n",
    "        assert scenario is not None\n",
    "        assert interval is not None\n",
    "        assert modality is not None\n",
    "        assert feature is not None\n",
    "        filename = '/'.join([PREFIX_PLOTS, scenario, paper, modality])\n",
    "        if subscenario is not None:\n",
    "            filename += '/' + '-'.join([feature, interval, subscenario, 'error-rates']) + '.eps'\n",
    "        else:\n",
    "            filename += '/' + '-'.join([feature, interval, 'error-rates']) + '.eps'\n",
    "    results = {}\n",
    "    for threshold in result_data:\n",
    "        # Prepare result and temporary variables\n",
    "        results[threshold] = {}\n",
    "        true_acc = 0.0\n",
    "        true_rej = 0.0\n",
    "        false_acc = 0.0\n",
    "        false_rej = 0.0\n",
    "        \n",
    "        # Load counts into the temporary vars\n",
    "        for s1 in result_data[threshold]:\n",
    "            for s2 in result_data[threshold][s1]:\n",
    "                true_acc += result_data[threshold][s1][s2][\"ta\"]\n",
    "                true_rej += result_data[threshold][s1][s2][\"tr\"]\n",
    "                false_acc += result_data[threshold][s1][s2][\"fa\"]\n",
    "                false_rej += result_data[threshold][s1][s2][\"fr\"]\n",
    "        \n",
    "        # Calculate error rates\n",
    "        # False Accept Rate (FAR)\n",
    "        fpr = false_acc / (false_acc + true_rej)\n",
    "        # False Reject Rate (FRR)\n",
    "        fnr = false_rej / (false_rej + true_acc)\n",
    "        # True Accept Rate (TAR)\n",
    "        tpr = true_acc / (true_acc + false_rej)\n",
    "        # True Reject Rate (TRR)\n",
    "        tnr = true_rej / (true_rej + false_acc)\n",
    "\n",
    "        # Put them in a data structure the visualization function understands\n",
    "        results[threshold] = {\"fpr\": fpr, \"fnr\": fnr, \"tpr\": tpr, \"tnr\": tnr}\n",
    "    \n",
    "    # Actually do the plotting of the error rates\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(sorted(results.keys()), [results[threshold][\"fpr\"] for threshold in sorted(results.keys())], '--', label='FAR')\n",
    "    ax.plot(sorted(results.keys()), [results[threshold][\"fnr\"] for threshold in sorted(results.keys())], label='FRR')\n",
    "    \n",
    "    # Determine the point where FAR and FRR are closest (i.e., the Equal Error Rate - EER)\n",
    "    for threshold in sorted(results.keys()):\n",
    "        if results[threshold][\"fpr\"] <= results[threshold][\"fnr\"]:\n",
    "            fpr = results[threshold][\"fpr\"]\n",
    "            fnr = results[threshold][\"fnr\"]\n",
    "            if abs(prev_fpr - prev_fnr) < abs(results[threshold][\"fpr\"] - results[threshold][\"fnr\"]):\n",
    "                fpr = prev_fpr\n",
    "                fnr = prev_fnr\n",
    "                threshold = prev_thres\n",
    "            print(\"Thresh\", threshold, \"FAR\", fpr, \"FRR\", fnr)\n",
    "            #ax.plot([threshold, threshold], [0.0, fnr], 'k-')\n",
    "            #ax.plot([0.0, threshold], [fnr, fnr], 'k-')\n",
    "            ax.set(xlabel='Similarity Threshold', ylabel='Error Rate', xlim=(xlow,xhigh))\n",
    "            ax.legend()\n",
    "            if save:\n",
    "                plt.savefig(filename, format='eps', dpi=1000)\n",
    "            plt.show()\n",
    "\n",
    "            return fpr, fnr, threshold\n",
    "        prev_fpr = results[threshold][\"fpr\"]\n",
    "        prev_fnr = results[threshold][\"fnr\"]\n",
    "        prev_thres = threshold\n",
    "\n",
    "\n",
    "def prune_results(result_data, prune):\n",
    "    \"\"\"Remove specific sensors from the results\n",
    "    \n",
    "    :param result_data: Result data, as formatted by gen_far_frr or the result import functions\n",
    "    :param prune: A list of dictionary keys (strings) to remove. Will remove any pair that involves at least\n",
    "        one of the provided keys (so if \"01\" should be removed, it will remove X->01 and 01->X for all keys X)\n",
    "    :return: the pruned result dataset\n",
    "    \"\"\"\n",
    "    # Make a deep copy of the dictionary, because we don't want to modify the original\n",
    "    result = copy.deepcopy(result_data)\n",
    "    # Go through the dictionary looking for keys to remove\n",
    "    for t in result:\n",
    "        # Ensure that we are not using an internal iterator on the dictionary, since we are about to modify the\n",
    "        # dictionary during iteration\n",
    "        for s1 in list(result[t].keys()):\n",
    "            if s1 in prune:\n",
    "                del(result[t][s1])\n",
    "            else:\n",
    "                # Ditto here\n",
    "                for s2 in list(result[t][s1]):\n",
    "                    if s2 in prune:\n",
    "                        del([result[t][s1][s2]])\n",
    "    return result\n",
    "\n",
    "\n",
    "def pair_error_rate(result_data, s1, s2, threshold):\n",
    "    \"\"\"Determine the error rate between sensors s1 and s2.\n",
    "    \n",
    "    :param result_data: Result data, as formatted by gen_far_frr or the result import functions\n",
    "    :param s1: The first sensor (string)\n",
    "    :param s2: The second sensor (string)\n",
    "    :param threshold: The threshold to use\n",
    "    :return: 4-tuple of FAR, FRR, TAR, TRR.\n",
    "    \"\"\"\n",
    "    # Ensure dataset meets expectations\n",
    "    assert threshold in result_data\n",
    "    if int(s1) > int(s2):\n",
    "        t = s1\n",
    "        s1 = s2\n",
    "        s2 = t\n",
    "    assert s1 in result_data[threshold]\n",
    "    assert s2 in result_data[threshold][s1]\n",
    "    \n",
    "    # Collect statistics\n",
    "    true_acc = result_data[threshold][s1][s2][\"ta\"]\n",
    "    true_rej = result_data[threshold][s1][s2][\"tr\"]\n",
    "    false_acc = result_data[threshold][s1][s2][\"fa\"]\n",
    "    false_rej = result_data[threshold][s1][s2][\"fr\"]\n",
    "    \n",
    "    # Calculate error rates\n",
    "    # False Accept Rate (FAR)\n",
    "    if false_acc + true_rej > 0:\n",
    "        fpr = false_acc / (false_acc + true_rej)\n",
    "    else:\n",
    "        fpr = None\n",
    "\n",
    "    # False Reject Rate (FRR)\n",
    "    if false_rej + true_acc > 0:\n",
    "        fnr = false_rej / (false_rej + true_acc)\n",
    "    else:\n",
    "        fnr = None\n",
    "\n",
    "    # True Accept Rate (TAR)\n",
    "    if true_acc + false_rej > 0:\n",
    "        tpr = true_acc / (true_acc + false_rej)\n",
    "    else:\n",
    "        tpr = None\n",
    "    \n",
    "    # True Reject Rate (TRR)\n",
    "    if true_rej + false_acc > 0:\n",
    "        tnr = true_rej / (true_rej + false_acc)\n",
    "    else:\n",
    "        tnr = None\n",
    "    \n",
    "    return (fpr, fnr, tpr, tnr)\n",
    "    \n",
    "    \n",
    "def plot_distributions(data, scenario, param, minv, maxv, legend=True, save=None):\n",
    "    \"\"\"Plot the distribution of values to see how far they overlap.\n",
    "    \n",
    "    :param data: The data to plot.\n",
    "    :param scenario: The scenario (S_CAR, S_OFFICE)\n",
    "    :param param: The parameter to look into (max_xcorrm ...)\n",
    "    :param minv: The minimum on the x-axis to show\n",
    "    :param maxv: The maximum on the x-axis to show\n",
    "    :param legend: Boolean indicating whether a legend should be printed\n",
    "    :param save: A path under which the plot should be saved, or None if it should not be saved.\"\"\"\n",
    "    colo = []\n",
    "    ncolo = []\n",
    "    if scenario == S_CAR or scenario == S_MOBILE:\n",
    "        for s1 in data:\n",
    "            for s2 in data[s1]:\n",
    "                for d in data[s1][s2]:\n",
    "                    if is_colocated(s1, s2, scenario, d):\n",
    "                        colo.append(data[s1][s2][d][param])\n",
    "                    else:\n",
    "                        ncolo.append(data[s1][s2][d][param])\n",
    "    else:\n",
    "        for s1 in data:\n",
    "            for s2 in data[s1]:\n",
    "                if is_colocated(s1, s2, scenario):\n",
    "                    for day in data[s1][s2]:\n",
    "                        for d in data[s1][s2][day]:\n",
    "                            if not math.isnan(data[s1][s2][day][d][param]):\n",
    "                                colo.append(data[s1][s2][day][d][param])\n",
    "                else:\n",
    "                    for day in data[s1][s2]:\n",
    "                        for d in data[s1][s2][day]:\n",
    "                            if not math.isnan(data[s1][s2][day][d][param]):\n",
    "                                ncolo.append(data[s1][s2][day][d][param])\n",
    "    plt.figure()\n",
    "    sns.kdeplot(colo, label=\"Colocated\")\n",
    "    ax = sns.kdeplot(ncolo, label=\"Non-colocated\", linestyle=\"--\")\n",
    "    # ax.set_xlabel(\"Similarity Percentage\", fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    if legend:\n",
    "        plt.legend(prop={'size': 14})\n",
    "    if not legend:\n",
    "        ax.legend().set_visible(False)\n",
    "    if 0.0 <= minv <= 1.0 and 0.0 <= maxv <= 1.0:\n",
    "        minlim = 0.0\n",
    "        maxlim = 1.0\n",
    "    elif 0.0 <= minv <= 100.0 and 0.0 <= maxv <= 100.0:\n",
    "        minlim = 0.0\n",
    "        maxlim = 100.0\n",
    "    else:\n",
    "        raise Exception(\"Not implemented\")\n",
    "    ax.set_xlim(minlim,maxlim)\n",
    "    if save is not None:\n",
    "        plt.savefig(save, format='eps', dpi=1000)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "At this point, we have defined all functions that we need for data analysis.\n",
    "\n",
    "To work with the FAR and FRR data, we need to first compute a series of accept and reject results for specific thresholds on the data. **This is an expensive operation** (on the order of up to a few days for large datasets like the office experiment), but it only needs to be run once - the results are cached on disk for future operations.\n",
    "\n",
    "If you have obtained this code together with the dataset, it should already contain these caches, no need to regenerate them unless you want to reproduce our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate caches and overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_spf(data, scenario):\n",
    "    mobile_lowered_threshold_35 = [6, 9, 16, 23]\n",
    "    mobile_lowered_threshold_38 = [5, 7, 8, 10, 15, 17, 22, 24, 25]\n",
    "    def mobile_threshold(s1, s2, power1, power2):\n",
    "        # Sound-proof has a minimum audio power threshold - readings that do not have enough power\n",
    "        # are discarded. Normally, this threshold is 40. However, for specific devices in the\n",
    "        # mobile scenario, we had to decrease the threshold due to different microphone\n",
    "        # characteristics. This is done through this function. See the paper for a discussion\n",
    "        # of this.\n",
    "        s1_limit = 40.0\n",
    "        s2_limit = 40.0\n",
    "        if s1 in mobile_lowered_threshold_35:\n",
    "            s1_limit = 35.0\n",
    "        if s2 in mobile_lowered_threshold_35:\n",
    "            s2_limit = 35.0\n",
    "        if s1 in mobile_lowered_threshold_38:\n",
    "            s1_limit = 38.0\n",
    "        if s2 in mobile_lowered_threshold_38:\n",
    "            s2_limit = 38.0\n",
    "        return power1 > s1_limit and power2 > s2_limit\n",
    "        \n",
    "    included = 0.0\n",
    "    excluded = 0.0\n",
    "    rv = {}\n",
    "    if scenario == S_CAR:\n",
    "        for s1 in data:\n",
    "            if s1 not in rv:\n",
    "                rv[s1] = {}\n",
    "            for s2 in data[s1]:\n",
    "                if s2 not in rv[s1]:\n",
    "                    rv[s1][s2] = {}\n",
    "                for ts in data[s1][s2]:\n",
    "                    if data[s1][s2][ts][\"power1_db\"] < 40.0 or data[s1][s2][ts][\"power2_db\"] < 40.0:\n",
    "                        # Does not meet cutoff\n",
    "                        excluded += 1\n",
    "                    else:\n",
    "                        included += 1\n",
    "                        rv[s1][s2][ts] = data[s1][s2][ts]\n",
    "    elif scenario == S_MOBILE:\n",
    "        for s1 in data:\n",
    "            if s1 not in rv:\n",
    "                rv[s1] = {}\n",
    "            for s2 in data[s1]:\n",
    "                if s2 not in rv[s1]:\n",
    "                    rv[s1][s2] = {}\n",
    "                for ts in data[s1][s2]:\n",
    "                    if not mobile_threshold(s1, s2, data[s1][s2][ts][\"power1_db\"], data[s1][s2][ts][\"power2_db\"]):\n",
    "                        # Does not meet cutoff\n",
    "                        excluded += 1\n",
    "                    else:\n",
    "                        included += 1\n",
    "                        rv[s1][s2][ts] = data[s1][s2][ts]\n",
    "    elif scenario == S_OFFICE:\n",
    "        for s1 in data:\n",
    "            if s1 not in rv:\n",
    "                rv[s1] = {}\n",
    "            for s2 in data[s1]:\n",
    "                if s2 not in rv[s1]:\n",
    "                    rv[s1][s2] = {}\n",
    "                for day in data[s1][s2]:\n",
    "                    if day not in rv[s1][s2]:\n",
    "                        rv[s1][s2][day] = {}\n",
    "                    for ts in data[s1][s2][day]:\n",
    "                        if data[s1][s2][day][ts][\"power1_db\"] < 40.0 or data[s1][s2][day][ts][\"power2_db\"] < 40.0:\n",
    "                            # Does not meet cutoff\n",
    "                            excluded += 1\n",
    "                        else:\n",
    "                            included += 1\n",
    "                            rv[s1][s2][day][ts] = data[s1][s2][day][ts]\n",
    "    else:\n",
    "        assert False, \"Unknown scenario identifier provided: \" + scenario\n",
    "    \n",
    "    \n",
    "    return rv, \"inc: \" + str(included / (included + excluded)) + \" (\" + str(int(included)) + \" / \" + str(int(included + excluded)) + \")\"\n",
    "\n",
    "SUB_LIST = {\n",
    "    S_CAR: [SU_PARKED, SU_CITY, SU_HIGHWAY],\n",
    "    S_OFFICE: [SU_WDAY, SU_NIGHT, SU_WEND],\n",
    "    S_MOBILE: [None]\n",
    "}\n",
    "\n",
    "# Generate the caches we want to use later\n",
    "for scenario in [S_CAR, S_OFFICE, S_MOBILE]:\n",
    "    for interval in reversed(INTERVALS):\n",
    "        for subscenario in SUB_LIST[scenario]:\n",
    "            print(scenario, subscenario, interval)\n",
    "            # Load the data\n",
    "            data = load_audio_feature(SOUNDPROOF, interval, scenario, subscenario=subscenario, strip=['power1_db', 'power2_db', 'max_xcorr'])\n",
    "            # Generate the FAR and FRR for a diverse set of thresholds\n",
    "            rv = gen_far_frr(scenario, data, 'max_xcorr', filter_func=filter_spf, minv=0.0, maxv=1.0, increments=3000)\n",
    "            # Save the resulting data as caches for later processing\n",
    "            save_result_json(rv, SOUNDPROOF, interval, scenario, 'max_xcorr', subscenario=subscenario)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have generated the caches, we can generate the actual results. This includes the actual error rates, the Equal Error Rates (EERs), and a few more statistics on all scenarios and subscenarios with all interval sizes. It also computes the robustness data (i.e, applying the EER threshold from one scenario on another dataset and seeing what the resulting error rates are)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIO_SET = set([S_CAR, S_OFFICE, S_MOBILE])\n",
    "SUB_LIST = {\n",
    "    S_CAR: [SU_PARKED, SU_CITY, SU_HIGHWAY, None],\n",
    "    S_OFFICE: [SU_WDAY, SU_NIGHT, SU_WEND, None],\n",
    "    S_MOBILE: [None]\n",
    "}\n",
    "\n",
    "\n",
    "SUB_SETS = {\n",
    "    S_CAR: set([SU_PARKED, SU_CITY, SU_HIGHWAY]),\n",
    "    S_OFFICE: set([SU_WDAY, SU_NIGHT, SU_WEND]),\n",
    "    S_MOBILE: set([None])\n",
    "}\n",
    "\n",
    "robustness_output = {}\n",
    "\n",
    "for interval in reversed(INTERVALS):\n",
    "    thresholds = {}\n",
    "    for scenario in SCENARIO_SET:\n",
    "        thresholds[scenario] = {}\n",
    "        for subscenario in SUB_LIST[scenario]:\n",
    "            thresholds[scenario][subscenario] = {}\n",
    "            print(scenario, subscenario, interval)\n",
    "            # Prepare output JSON\n",
    "            result = {\"base\": {}, \"adversarial\": {}}\n",
    "            \n",
    "            # Check if we have cached results\n",
    "            if not result_exists(SOUNDPROOF, interval, scenario, 'max_xcorr', subscenario=subscenario):\n",
    "                print(\"No caches found, please generate caches first (see code further up)\")\n",
    "                break\n",
    "            else:\n",
    "                # We have cached results, load them\n",
    "                print(\"Using cached results...\")\n",
    "                rv = load_result(SOUNDPROOF, interval, scenario, 'max_xcorr', subscenario=subscenario)            \n",
    "            \n",
    "            # Plot the error rates and determine the EER\n",
    "            far, frr, thresh = plot_far_frr(rv, xlow=0.0, xhigh=0.40, save=True, paper=SOUNDPROOF, scenario=scenario, subscenario=subscenario, modality='audio', feature='max_xcorr', interval=interval)\n",
    "            # Save to results\n",
    "            result[\"base\"][\"eer\"] = {\"far\": far, \"frr\": frr, \"threshold\": thresh}\n",
    "            # Save to thresholds dictionary for later robustness checks\n",
    "            thresholds[scenario][subscenario][\"eer\"] = {\"threshold\": thresh, \"far\": far, \"frr\": frr}\n",
    "            \n",
    "            # Try a number of target false accept rates to determine the respective FRR and threshold\n",
    "            for target_far in [0.001, 0.005, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045, 0.05]:\n",
    "                far, frr, threshold = frr_for_far(rv, target_far)\n",
    "                # Save to results\n",
    "                result[\"base\"][\"far_%s\" % target_far] = {\"far\": far, \"frr\": frr, \"threshold\": threshold}\n",
    "                # ...and thresholds\n",
    "                thresholds[scenario][subscenario][\"far_%s\" % target_far] = {\"threshold\": threshold, \"far\": far, \"frr\": frr}\n",
    "                # print(\"Target FAR:\", target_far, \"Observed FAR:\", far, \"FRR\", frr, \"with threshold\", threshold)\n",
    "            # print(\"\")\n",
    "            \n",
    "            save_result_json(result, SOUNDPROOF, interval, scenario, 'max_xcorr', subscenario=subscenario, suffix=\"rates\")\n",
    "            \n",
    "            print(\"\")\n",
    "            print(\"\")\n",
    "        \n",
    "    # At this point, the thresholds dictionary should contain information for all scenarios and subscenarios\n",
    "    # We will now perform robustness checks.  This means that we are interested in how well the performance\n",
    "    # holds up if we start using the optimal threshold from one scenario on the other scenario, and the same\n",
    "    # for subscenarios within each scenario.  This is written less efficiently than it could be, in the interest\n",
    "    # of simpler code - loading all result caches twice does not have a massive impact on the performance.\n",
    "    print(\"Generating robustness data...\")\n",
    "    for scenario in SCENARIO_SET:\n",
    "        result = {scenario: {}}\n",
    "        for subscenario in SUB_LIST[scenario]:\n",
    "            \n",
    "            error_rates = [\"far_%s\" % rate for rate in [0.001, 0.005, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045, 0.05]]\n",
    "            error_rates.append(\"eer\")\n",
    "            \n",
    "            # We have cached results, load them\n",
    "            print(\"Using cached results...\")\n",
    "            rv = load_result(SOUNDPROOF, interval, scenario, 'max_xcorr', subscenario=subscenario)\n",
    "            \n",
    "            if subscenario is None:\n",
    "                \n",
    "                # This is a \"global\" result (no specific subscenario) - compare with other scenario\n",
    "                for target in SCENARIO_SET - set([scenario]):\n",
    "                \n",
    "                    result[scenario][target] = {}\n",
    "                    for error_rate in error_rates:\n",
    "                        threshold = thresholds[target][None][error_rate][\"threshold\"]\n",
    "                        orig_far = thresholds[scenario][None][error_rate][\"far\"]\n",
    "                        orig_frr = thresholds[scenario][None][error_rate][\"frr\"]\n",
    "\n",
    "                        far, frr = error_rate_for_threshold(rv, threshold)\n",
    "                        result[scenario][target][error_rate] = {\n",
    "                            \"threshold\": threshold, \n",
    "                            \"far\": far, \n",
    "                            \"frr\": frr,\n",
    "                        }\n",
    "                        if error_rate == \"eer\":\n",
    "                            result[scenario][target][error_rate][\"orig_far\"] = orig_far\n",
    "                            result[scenario][target][error_rate][\"orig_frr\"] = orig_frr\n",
    "                            \n",
    "                            if scenario not in robustness_output:\n",
    "                                robustness_output[scenario] = {target: {}}\n",
    "                            if target not in robustness_output[scenario]:\n",
    "                                robustness_output[scenario][target] = {}\n",
    "                            \n",
    "                            try:\n",
    "                                far_change_rel = (orig_far / far) * 100\n",
    "                            except ZeroDivisionError:\n",
    "                                far_change_rel = np.nan\n",
    "                                \n",
    "                            try:\n",
    "                                frr_change_rel = (orig_frr / frr) * 100\n",
    "                            except ZeroDivisionError:\n",
    "                                frr_change_rel = np.nan\n",
    "                            robustness_output[scenario][target][interval] = {\n",
    "                                \"far\": far, \n",
    "                                \"frr\": frr,\n",
    "                                \"orig_far\": orig_far,\n",
    "                                \"orig_frr\": orig_frr,\n",
    "                                \"far_change_abs\": orig_far - far,\n",
    "                                \"frr_change_abs\": orig_frr - frr,\n",
    "                                \"far_change_rel\": far_change_rel,\n",
    "                                \"frr_change_rel\": frr_change_rel\n",
    "                            }\n",
    "                \n",
    "            else:  # Subscenario is not None\n",
    "                result[subscenario] = {}\n",
    "                # Iterate through all other subscenarios\n",
    "                for target_ss in SUB_SETS[scenario] - set([subscenario]):\n",
    "                    result[subscenario][target_ss] = {}\n",
    "                    for error_rate in error_rates:\n",
    "                        threshold = thresholds[scenario][target_ss][error_rate][\"threshold\"]\n",
    "                        orig_far = thresholds[scenario][subscenario][error_rate][\"far\"]\n",
    "                        orig_frr = thresholds[scenario][subscenario][error_rate][\"frr\"]\n",
    "                        \n",
    "                        far, frr = error_rate_for_threshold(rv, threshold)\n",
    "                        result[subscenario][target_ss][error_rate] = {\n",
    "                            \"threshold\": threshold, \n",
    "                            \"far\": far, \n",
    "                            \"frr\": frr,\n",
    "                        }\n",
    "                        if error_rate == \"eer\":\n",
    "                            result[subscenario][target_ss][error_rate][\"orig_far\"] = orig_far\n",
    "                            result[subscenario][target_ss][error_rate][\"orig_frr\"] = orig_frr\n",
    "                            \n",
    "                            if scenario not in robustness_output:\n",
    "                                robustness_output[scenario] = {}\n",
    "                            if subscenario not in robustness_output[scenario]:\n",
    "                                robustness_output[scenario][subscenario] = {}\n",
    "                            if target_ss not in robustness_output[scenario][subscenario]:\n",
    "                                robustness_output[scenario][subscenario][target_ss] = {}\n",
    "                            try:\n",
    "                                far_change_rel = (orig_far / far) * 100\n",
    "                            except ZeroDivisionError:\n",
    "                                far_change_rel = np.nan\n",
    "                                \n",
    "                            try:\n",
    "                                frr_change_rel = (orig_frr / frr) * 100\n",
    "                            except ZeroDivisionError:\n",
    "                                frr_change_rel = np.nan\n",
    "                            robustness_output[scenario][subscenario][target_ss][interval] = {\n",
    "                                \"far\": far, \n",
    "                                \"frr\": frr,\n",
    "                                \"orig_far\": orig_far,\n",
    "                                \"orig_frr\": orig_frr,\n",
    "                                \"far_change_abs\": orig_far - far,\n",
    "                                \"frr_change_abs\": orig_frr - frr,\n",
    "                                \"far_change_rel\": far_change_rel,\n",
    "                                \"frr_change_rel\": frr_change_rel\n",
    "                            }\n",
    "        # Save the results\n",
    "        save_result_json(result, SOUNDPROOF, interval, scenario, 'max_xcorr', subscenario=\"robustness\", suffix=\"summary\")\n",
    "\n",
    "for scenario in SCENARIO_SET:\n",
    "    for scenario2 in SCENARIO_SET - set([scenario]):\n",
    "        # \"scenario\" is the used dataset, scenario2 is the one whose threshold was used\n",
    "        print(\"Robustness\", scenario, scenario2)\n",
    "        # What do these abbreviations mean?\n",
    "        # - Int = Interval that was used\n",
    "        # - FAR and FRR = Obtained false accept / reject rates\n",
    "        # - ofar and ofrr = Original FAR and FRR from the base scenario, for comparison\n",
    "        # - sprd = spread between FAR and FRR, i.e. abs(FAR - FRR)\n",
    "        # - osprd = Spread between original FAR and FRR, i.e. abs(ofar - ofrr)\n",
    "        # - aca and rca = Absolute change in false accept / reject rate, i.e. ofar - far\n",
    "        # - tca = Absolute changes summed up, i.e. aca + rca\n",
    "        # - acr and rcr = Relative changes in FAR and FRR, i.e. (ofar / far) * 100\n",
    "        # - oeer = original EER\n",
    "        # - eer = new EER, i.e. (far + frr) / 2.0\n",
    "        # - eerabs = absolute change in EER\n",
    "        print(\"Int\", \"FAR\", \"FRR\", \"ofar\", \"ofrr\", \"sprd\", \"osprd\", \"aca\", \"rca\", \"acr\", \"rcr\", \"oeer\", \"eer\", \"eerabs\", sep='\\t|')\n",
    "        print(\"-\" + \"-------+\"*13 + \"-------\")\n",
    "        scenpair = robustness_output[scenario][scenario2]\n",
    "        for interval in INTERVALS:\n",
    "            oeer = (scenpair[interval]['orig_far'] + scenpair[interval]['orig_frr']) / 2.0\n",
    "            eer = (scenpair[interval]['far'] + scenpair[interval]['frr']) / 2.0\n",
    "            ospread = abs(scenpair[interval]['orig_far'] - scenpair[interval]['orig_frr'])\n",
    "            spread = abs(scenpair[interval]['far'] - scenpair[interval]['frr'])\n",
    "            print(interval, \n",
    "                  round(scenpair[interval]['far'], 3), \n",
    "                  round(scenpair[interval]['frr'], 3), \n",
    "                  round(scenpair[interval]['orig_far'], 3), \n",
    "                  round(scenpair[interval]['orig_frr'], 3), \n",
    "                  round(spread, 3),\n",
    "                  round(ospread, 3),\n",
    "                  round(scenpair[interval]['far_change_abs'], 3), \n",
    "                  round(scenpair[interval]['frr_change_abs'], 3),\n",
    "                  round(scenpair[interval]['far_change_rel'], 1), \n",
    "                  round(scenpair[interval]['frr_change_rel'], 1),\n",
    "                  round(oeer, 3),\n",
    "                  round(eer, 3),\n",
    "                  round(oeer - eer, 3),\n",
    "                  sep='\\t|')\n",
    "        print(\"\")\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "for scenario in SCENARIO_SET:\n",
    "    for subscenario in SUB_LIST[scenario]:\n",
    "        for target_ss in SUB_LIST[scenario]:\n",
    "            if target_ss == subscenario or target_ss is None or subscenario is None:\n",
    "                continue\n",
    "            \n",
    "            print(\"Robustness\", scenario, subscenario, target_ss)\n",
    "            print(\"Int\", \"FAR\", \"FRR\", \"ofar\", \"ofrr\", \"sprd\", \"osprd\", \"aca\", \"rca\", \"acr\", \"rcr\", \"oeer\", \"eer\", \"eerabs\", sep='\\t|')\n",
    "            print(\"-\" + \"-------+\"*13 + \"-------\")\n",
    "            scenpair = robustness_output[scenario][subscenario][target_ss]\n",
    "            for interval in INTERVALS:\n",
    "                oeer = (scenpair[interval]['orig_far'] + scenpair[interval]['orig_frr']) / 2.0\n",
    "                eer = (scenpair[interval]['far'] + scenpair[interval]['frr']) / 2.0\n",
    "                ospread = abs(scenpair[interval]['orig_far'] - scenpair[interval]['orig_frr'])\n",
    "                spread = abs(scenpair[interval]['far'] - scenpair[interval]['frr'])\n",
    "                print(interval, \n",
    "                      round(scenpair[interval]['far'], 3), \n",
    "                      round(scenpair[interval]['frr'], 3), \n",
    "                      round(scenpair[interval]['orig_far'], 3), \n",
    "                      round(scenpair[interval]['orig_frr'], 3),\n",
    "                      round(spread, 3),\n",
    "                      round(ospread, 3),\n",
    "                      round(scenpair[interval]['far_change_abs'], 3), \n",
    "                      round(scenpair[interval]['frr_change_abs'], 3),\n",
    "                      round(scenpair[interval]['far_change_rel'], 1), \n",
    "                      round(scenpair[interval]['frr_change_rel'], 1),\n",
    "                      round(oeer, 3),\n",
    "                      round(eer, 3),\n",
    "                      round(oeer - eer, 3),\n",
    "                      sep='\\t|')\n",
    "            print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
